{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM7CXkHncef43eA7jllT35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyLpr/defi_ia/blob/main/feature_engineering/stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce notebook on va rassembler toutes nos données dans le but d'obtenir le stock de chaque hôtel à chaque date. Il y aura des données manquantes que nous allons inférer dans un second temps."
      ],
      "metadata": {
        "id": "m0Y78gIG14VN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import des librairies et des données"
      ],
      "metadata": {
        "id": "2HvRVzIB1y4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Cix4xryK1wxP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_vienna = pd.read_csv(\"vienna.csv\")\n",
        "df_vilnius = pd.read_csv(\"vilnius.csv\")\n",
        "df_amsterdam = pd.read_csv(\"amsterdam.csv\")\n",
        "df_rome = pd.read_csv(\"rome.csv\")\n",
        "df_valletta = pd.read_csv(\"valletta.csv\")\n",
        "df_paris = pd.read_csv(\"paris.csv\")\n",
        "df_madrid = pd.read_csv(\"madrid.csv\")\n",
        "df_copenhagen = pd.read_csv(\"copenhagen.csv\")\n",
        "df_sofia = pd.read_csv(\"sofia.csv\")\n",
        "df = pd.concat([df_vienna, df_vilnius, df_amsterdam, df_rome, df_valletta, df_paris, df_madrid, df_copenhagen, df_sofia])\n",
        "df_test = pd.read_csv(\"test_set.csv\")"
      ],
      "metadata": {
        "id": "7APbiEeQ123-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des stocks issus des requêtes et du test set"
      ],
      "metadata": {
        "id": "kk3Yji692cdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock_list = []\n",
        "for hotel in range(0, 999):\n",
        "  df_hot = df[df[\"hotel_id\"] == hotel]\n",
        "  df_hot_test = df_test[df_test[\"hotel_id\"] == hotel]\n",
        "  stock_per_hotel = []\n",
        "  for date in range(0, 45):\n",
        "    df_hot_date = df_hot[df_hot[\"date\"] == date]\n",
        "    df_hot_test_date = df_hot_test[df_hot_test[\"date\"] == date]\n",
        "    if len(df_hot_date) > 0:\n",
        "      stock = df_hot_date[\"stock\"].mean() # moyenne inutile ici, c'est juste pour transformer en valeur\n",
        "    else:\n",
        "      stock = df_hot_test_date[\"stock\"].mean() # cas NaN compris ici\n",
        "    stock_per_hotel.append(stock)\n",
        "  stock_list.append(stock_per_hotel)"
      ],
      "metadata": {
        "id": "LR_bLcqz2jOl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock = pd.DataFrame(data = stock_list)\n",
        "df_na = df_stock[df_stock.isna().any(axis=1)]\n",
        "df_no_na = df_stock.dropna()"
      ],
      "metadata": {
        "id": "axGGKA6W23F3"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inférence des valeurs manquantes"
      ],
      "metadata": {
        "id": "zqBZHyUt5A5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df_na.iterrows():\n",
        "  rowcopy = row.copy()\n",
        "  list_index = []\n",
        "  list_dist = []\n",
        "  list_na = []\n",
        "  list_row = []\n",
        "  newrow = []\n",
        "  # on connaît les jours pour lesquels les stocks sont toujours manquants pour ces hôtels\n",
        "  list_na = [7, 8, 9, 10, 11, 12, 13, 14, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
        "  for i in sorted(list_na, reverse=True):\n",
        "      del row[i]\n",
        "  normalized_row = normalize([row])  \n",
        "  for index2, row2 in df_no_na.iterrows():\n",
        "    for i in sorted(list_na, reverse=True):\n",
        "      del row2[i]\n",
        "    normalized_row2 = normalize([row2])\n",
        "    dist = distance.euclidean(normalized_row, normalized_row2)\n",
        "    list_index.append(index2)\n",
        "    list_dist.append(dist)\n",
        "    list_row.append(row2)\n",
        "  indice_min = np.argmin(list_dist)\n",
        "  voisin = df_no_na.iloc[indice_min]\n",
        "\n",
        "  # pour afficher les paires hotel de df_na et son + proche voisin\n",
        "  #print(index, voisin.name)\n",
        "\n",
        "  # calcul du coeff entre les 2 hôtels voisins\n",
        "  bg_A_1, bd_A_1, bg_A_2, bd_A_2 = row[6], row[15], row[21], row[34] # pour l'hôtel à stocks manquants\n",
        "  bg_B_1, bd_B_1, bg_B_2, bd_B_2 = row2[6], row2[15], row2[21], row2[34] # pour le voisin\n",
        "  x = row.values.tolist()\n",
        "  y = list_row[indice_min].values.tolist()\n",
        "  rapport_list = []\n",
        "  for i in range(0, len(x)):\n",
        "    if x[i] != 0 and y[i] != 0: \n",
        "      rapport_list.append(x[i] / y[i])\n",
        "  coeff = round(np.mean(rapport_list), 2)\n",
        "\n",
        "  # remplissage des trous dans les stocks\n",
        "  for j in range(len(rowcopy)):\n",
        "    if j in [7, 8, 9, 10, 11, 12, 13, 14]: # premier trou\n",
        "      if bg_B_1 == bd_B_1: # cas borne gauche = borne droite, on remplit par cette valeur\n",
        "        newrow.append(bg_A_1)\n",
        "      else:\n",
        "        estimation = round(voisin[j]*coeff)\n",
        "        if (estimation < bg_A_1) & (bg_A_1 !=0): # cas estimation < borne gauche, absurde car le stock croît avec la variable date\n",
        "          newrow.append(bg_A_1)\n",
        "        elif estimation > bd_A_1: # cas estimation > borne droite, absurde pour la même raison\n",
        "          newrow.append(bd_A_1)\n",
        "        else:\n",
        "          newrow.append(round(voisin[j]*coeff))\n",
        "    elif j in [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]: # second trou\n",
        "      if bg_B_2 == bd_B_2: # cas borne gauche = borne droite, on remplit par cette valeur\n",
        "        newrow.append(bg_A_2)\n",
        "      else:\n",
        "        estimation = round(voisin[j]*coeff)\n",
        "        if (estimation < bg_A_2) & (bg_A_2 !=0): \n",
        "          newrow.append(bg_A_2)\n",
        "        elif estimation > bd_A_2: \n",
        "          newrow.append(bd_A_2)\n",
        "        else:\n",
        "          newrow.append(estimation)\n",
        "    else:\n",
        "      newrow.append(rowcopy[j])\n",
        "  df_na.at[index] = newrow"
      ],
      "metadata": {
        "id": "gkgJWUA15C2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export des résultats"
      ],
      "metadata": {
        "id": "iqLIWKfALCgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock = pd.concat([df_na, df_no_na])\n",
        "df_stock.to_csv(\"stock.csv\", index = False)"
      ],
      "metadata": {
        "id": "9qqbDTPeJyzo"
      },
      "execution_count": 116,
      "outputs": []
    }
  ]
}